#!/usr/bin/env python

import operator
import sys

import numpy as np
from scipy import linalg
import pandas as pd
from common import basics
from common.createDataSet import CreateDataSet
from common.tfidf import TfIdf
from sklearn.decomposition import LatentDirichletAllocation

# get input from shell
if len(sys.argv) != 2:
    print("Use ---> print_genre_vector genres")
    exit(0)

genre = sys.argv[1]

# variable init
movie_tag_map = {}
movie_timestamp_map = {}
data_set = CreateDataSet()
tagid_tag_map = {}
tfidf = TfIdf()

# PART 1 -  get of movies based on genre

sym = data_set.get_symbol_list(data_set.get_movies_by_genre(genre.split("|")))

# PART 2 - get complete data set
# Get all the tags for movies for give genre
movie_tag_query = "select movieid,tagid,timestamp,tag from (`movieid xgroup select  movieid,tagid,timestamp,tag:tagid.tag from .moviedata.mltags) where movieid in `$string("+sym+")"

# Execute Query

movie_tag_data = data_set.get_data_from_kdb(movie_tag_query)

# Add  tag-movie and tag-timestamp relationship to map

for elem in movie_tag_data:
    movie_tag_map[elem[0]] = np.array(elem[1]).tolist()
    movie_timestamp_map[elem[0]] = np.array(elem[2]).tolist()
    tagid_tag_map.update(dict(zip(np.array(elem[1]).tolist(), np.array(elem[3]).tolist())))

# PART 3 - TF IDF

# Calculate TF per document

for key in movie_tag_map:
    tfidf.calculate_tf(key, movie_tag_map[key])

# Normalize data
timestamp_data = {'timestamp': basics.combine_map_value_list(movie_timestamp_map)}
df = data_set.normalize_data(timestamp_data)
normalized_timestamp = df['timestamp'].tolist()

# Calculate time weighted TF
tfidf.calculate_timeweighted_tf(movie_tag_map, normalized_timestamp)

# Calculate TF-IDF for all documents
tfidf.calculate_tfidf()

################################################################
#
#                       <----PHASE 2---->
#
#
#################################################################

# calculate all tags and all movies



alltags = basics.combine_map_value_list(movie_tag_map)
allmovies = movie_tag_map.keys()

# create object feature matrix with zero values
object_feature_matrix = np.zeros(shape=(len(allmovies),len(alltags)))
# fill up the matrix
object_feature_matrix = basics.fill_matrix(object_feature_matrix, allmovies, alltags, tfidf.tfidf)

# PCA computation

# object feature covariance matrix
object_feature_covariance =  np.cov(object_feature_matrix.transpose())


# compute PCA and get 4 components
U, S, VT = linalg.svd(object_feature_covariance, full_matrices=False)

# print top 4
print("---------Top Four Features------------")
print("\n 1.PCA")
print(pd.DataFrame(VT).head(4))


# SVD computation

U, S, VT = linalg.svd(object_feature_matrix, full_matrices=False)
print("\n 2.SVD")
print(pd.DataFrame(VT).head(4))


# create object feature matrix with zero values
object_feature_matrix = np.zeros(shape=(len(allmovies),len(alltags)))
# fill up the matrix
object_feature_matrix = basics.fill_matrix_count(object_feature_matrix, movie_tag_map,allmovies, alltags)
# LDA computation
print("\n 2.LDA")
lda = LatentDirichletAllocation(n_components=4, max_iter=5,
                                learning_method='online',
                                learning_offset=50.,
                                random_state=0)
lda.fit_transform(object_feature_matrix)

print(lda.components_)
